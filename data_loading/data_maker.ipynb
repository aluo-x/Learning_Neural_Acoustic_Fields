{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.transforms import Spectrogram\n",
    "import librosa\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e83555",
   "metadata": {},
   "source": [
    "# Misc functions to make spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path_name, use_torch=True, resample=True, resample_rate=22050):\n",
    "    # returns in shape (ch, num_sample), as float32 (on Linux at least)\n",
    "    # by default torchaudio is wav_arr, sample_rate\n",
    "    # by default wavfile is sample_rate, wav_arr\n",
    "    if use_torch:\n",
    "        loaded = torchaudio.load(path_name)\n",
    "        wave_data_loaded = loaded[0].numpy()\n",
    "        sr_loaded = loaded[1]\n",
    "    else:\n",
    "        loaded = wavfile.read(path_name)\n",
    "        wave_data_loaded = np.clip(loaded[1], -1.0, 1.0).T\n",
    "        sr_loaded = loaded[0]\n",
    "\n",
    "    if resample:\n",
    "        if wave_data_loaded.shape[1]==0:\n",
    "            print(\"len 0\")\n",
    "            assert False\n",
    "        if wave_data_loaded.shape[1]<int(sr_loaded*0.1):\n",
    "            padded_wav = librosa.util.fix_length(wave_data_loaded, int(sr_loaded*0.1))\n",
    "            resampled_wave = librosa.resample(padded_wav, orig_sr=sr_loaded, target_sr=resample_rate)\n",
    "        else:\n",
    "            resampled_wave = librosa.resample(wave_data_loaded, orig_sr=sr_loaded, target_sr=resample_rate)\n",
    "    else:\n",
    "        resampled_wave = wave_data_loaded\n",
    "    return np.clip(resampled_wave, -1.0, 1.0)\n",
    "\n",
    "def if_compute(arg):\n",
    "    unwrapped_angle = np.unwrap(arg).astype(np.single)\n",
    "    return np.concatenate([unwrapped_angle[:,:,0:1], np.diff(unwrapped_angle, n=1)], axis=-1)\n",
    "\n",
    "class get_spec():\n",
    "    def __init__(self, use_torch=False, power_mod=2, fft_size=512):\n",
    "        self.n_fft=fft_size\n",
    "        self.hop = self.n_fft//4\n",
    "        if use_torch:\n",
    "            assert False\n",
    "            self.use_torch = True\n",
    "            self.spec_transform = Spectrogram(power=None, n_fft=self.n_fft, hop_length=self.hop)\n",
    "        else:\n",
    "            self.power = power_mod\n",
    "            self.use_torch = False\n",
    "            self.spec_transform = None\n",
    "        \n",
    "    def transform(self, wav_data_prepad):\n",
    "        wav_data = librosa.util.fix_length(wav_data_prepad, wav_data_prepad.shape[-1]+self.n_fft//2)\n",
    "        if wav_data.shape[1]<4410:\n",
    "            wav_data = librosa.util.fix_length(wav_data, 4410)\n",
    "        if self.use_torch:\n",
    "            transformed_data = self.spec_transform(torch.from_numpy(wav_data)).numpy()\n",
    "        else:\n",
    "            \n",
    "            transformed_data = np.array([librosa.stft(wav_data[0],n_fft=self.n_fft, hop_length=self.hop),\n",
    "               librosa.stft(wav_data[1],n_fft=self.n_fft, hop_length=self.hop)])[:,:-1]\n",
    "#         print(np.array([librosa.stft(wav_data[0],n_fft=self.n_fft, hop_length=self.hop),\n",
    "#                librosa.stft(wav_data[1],n_fft=self.n_fft, hop_length=self.hop)]).shape, \"OLD SHAPE\")\n",
    "\n",
    "        real_component = np.abs(transformed_data)\n",
    "        img_component = np.angle(transformed_data)\n",
    "        gen_if = if_compute(img_component)/np.pi\n",
    "        return np.log(real_component+1e-3), gen_if, img_component\n",
    "\n",
    "def get_wave_if(input_stft, input_if):\n",
    "    # 2 chanel input of shape [2,freq,time]\n",
    "    # First input is logged mag\n",
    "    # Second input is if divided by np.pi\n",
    "    padded_input_stft = np.concatenate((input_stft, input_stft[:,-1:]), axis=1)\n",
    "    padded_input_if = np.concatenate((input_if, input_if[:,-1:]*0.0), axis=1)\n",
    "    unwrapped = np.cumsum(padded_input_if, axis=-1)*np.pi\n",
    "    phase_val = np.cos(unwrapped) + 1j * np.sin(unwrapped)\n",
    "    restored = (np.exp(padded_input_stft)-1e-3)*phase_val\n",
    "    wave1 = librosa.istft(restored[0], hop_length=512//4)\n",
    "    wave2 = librosa.istft(restored[1], hop_length=512//4)\n",
    "    return wave1, wave2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692f84a",
   "metadata": {},
   "source": [
    "# Loop through to audio\n",
    "1. Resample to 22050 Hz\n",
    "2. Make each log magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7185595",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f_mag.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    f_phase.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "raw_path = \"/media/aluo/big2/soundspaces_full/binaural_rirs/replica\"\n",
    "mag_path = \"/media/aluo/big2/soundspaces_full/magnitudes\"\n",
    "phase_path = \"/media/aluo/big2/soundspaces_full/phases\"\n",
    "spec_getter = get_spec()\n",
    "room_names = os.listdir(raw_path)\n",
    "print(room_names)\n",
    "for room_name in room_names:\n",
    "    length_tracker = []\n",
    "    print(room_name)\n",
    "    room_path = os.path.join(raw_path, room_name)\n",
    "    mag_object = os.path.join(mag_path, room_name)\n",
    "    phase_object = os.path.join(phase_path, room_name)\n",
    "    f_mag = h5py.File(mag_object+\".h5\", 'w')\n",
    "    f_phase = h5py.File(phase_object+\".h5\", 'w')\n",
    "    zz = 0\n",
    "    for orientation in [\"0\", \"90\", \"180\", \"270\"]:\n",
    "        ori_path = os.path.join(room_path, orientation)\n",
    "        files = sorted(os.listdir(ori_path))\n",
    "        files = [_ for _ in files if \"wav\" in _]\n",
    "        if orientation == \"0\":\n",
    "            print(\"Found {} files\".format(str(len(files)*4)))\n",
    "            \n",
    "        for ff in files:\n",
    "            zz+= 1 \n",
    "            if zz % 500==0:\n",
    "                print(zz)\n",
    "            cur_file = os.path.join(ori_path, ff)\n",
    "            try:\n",
    "                loaded_wav = load_audio(cur_file, use_torch=False)\n",
    "            except Exception as e:\n",
    "                print(\"0 length wav\", cur_file, e)\n",
    "                continue\n",
    "            real_spec, img_spec, raw_phase = spec_getter.transform(loaded_wav)\n",
    "            length_tracker.append(real_spec.shape[2])\n",
    "#             reconstructed_wave = get_wave_if(real_spec, img_spec)\n",
    "#             plt.imshow(real_spec[0])\n",
    "#             plt.show()\n",
    "#             plt.imshow(img_spec[0])\n",
    "#             plt.show()\n",
    "            f_mag.create_dataset('{}_{}'.format(orientation, ff.split(\".\")[0]), data=real_spec.astype(np.half))\n",
    "            f_phase.create_dataset('{}_{}'.format(orientation, ff.split(\".\")[0]), data=img_spec.astype(np.half))\n",
    "    print(\"Max length {}\".format(room_name), np.max(length_tracker))\n",
    "    f_mag.close()\n",
    "    f_phase.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19beb9a5",
   "metadata": {},
   "source": [
    "# Compute mean std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(input_arr, max_len_in, constant=np.log(1e-3)):\n",
    "    return np.pad(input_arr, [[0,0],[0,0],[0,max_len_in-input_arr.shape[2]]], constant_values=constant)\n",
    "    \n",
    "raw_path = \"/media/aluo/big2/soundspaces_full/magnitudes\"\n",
    "mean_std = \"/media/aluo/big2/soundspaces_full/magnitude_mean_std\"\n",
    "\n",
    "max_len_dict = {\"apartment_1\": 101, \"apartment_2\": 86, \"frl_apartment_2\": 107, \"frl_apartment_4\": 103, \"office_4\": 78, \"room_2\": 84}\n",
    "\n",
    "files = os.listdir(raw_path)\n",
    "for f_name_old in sorted(list(max_len_dict.keys())):\n",
    "    f_name = f_name_old+\".h5\"\n",
    "    print(\"Processing \", f_name)\n",
    "    f = h5py.File(os.path.join(raw_path, f_name), 'r')\n",
    "    keys = list(f.keys())\n",
    "    max_len = max_len_dict[f_name.split(\".\")[0]]\n",
    "    all_arrs = []\n",
    "    for idx in np.random.choice(len(keys), 4000, replace=False):  \n",
    "        all_arrs.append(pad(f[keys[idx]], max_len).astype(np.single))\n",
    "    all_arrs_2 = np.array(all_arrs, copy=False, dtype=np.single)\n",
    "    print(\"Computing mean\")\n",
    "    mean_val = np.mean(all_arrs, axis=(0,1))\n",
    "    print(\"Computing std\")\n",
    "    std_val = np.std(all_arrs, axis=(0,1))+0.1\n",
    "    \n",
    "    plt.imshow(all_arrs[0][0])\n",
    "    plt.show()\n",
    "    plt.imshow(mean_val)\n",
    "    plt.show()\n",
    "    plt.imshow(std_val)\n",
    "    plt.show()\n",
    "    print(mean_val.shape)\n",
    "    del all_arrs\n",
    "    f.close()\n",
    "    gc.collect()\n",
    "    with open(os.path.join(mean_std, f_name.replace(\"h5\", \"pkl\")), \"wb\") as mean_std_file:\n",
    "        pickle.dump([mean_val, std_val], mean_std_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
